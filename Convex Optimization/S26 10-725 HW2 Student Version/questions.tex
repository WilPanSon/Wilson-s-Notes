\section{Implications of Smoothness and Strong Convexity (20 points) - Julia}  


Let $f$ be convex and twice differentiable.

\begin{enumerate}
\item \textbf{(10 pts)} Show that the following statements are equivalent. 
\begin{enumerate}
\item $\nabla f$ is Lipschitz with constant $\beta$;
\item $(\nabla f(x) - \nabla f(y))^T(x-y) \leq \beta \|x-y\|_2^2$ for all
  $x,y$; 
\item $\nabla^2 f(x) \preceq \beta I$ for all $x$;
\item $f(y) \leq f(x) + \nabla f(x)^T (y-x) + \frac{\beta}{2} \|y-x\|_2^2$
  for all $x,y$.
\end{enumerate}
We suggest that you prove (a) $\Rightarrow$ (b), (b)
$\Rightarrow$ (c), (c) $\Rightarrow$ (d), (d) $\Rightarrow$ (b), and (c)
$\Rightarrow$ (a). You are welcome to try alternative approaches, but your response will be graded with respect to these 5 parts. 

\textbf{Hints:} You can use the following property of
the directional derivative of $g: \mathbb{R}^n\to \mathbb{R}$ at $h$, where $\|h\|_2=1$: 
$$
\nabla g(x)^T h =
\lim_{t\rightarrow 0}\frac{g(x+th) -  g(x)}{t}.
$$
As an application of this, we have that $$
\nabla^2 f(x) h =
\lim_{t\rightarrow 0}\frac{\nabla f(x+th) - \nabla f(x)}{t}.
$$
Also recall the Taylor expansion with Lagrange form for
the remainder:
\begin{align*}
f(y) &= f(x) + \nabla f(x)^T(y-x) + \frac{1}{2}(y-x)^T\nabla^2 f(\lambda x +
       (1-\lambda)y) (y-x) .
\end{align*}
Finally, recall the integral form of the mean-value theorem: we have that for all $x, y$:
$$
\nabla f(y) - \nabla f(x) = \int_0^1 \nabla^2 f(x + t(y-x))(y-x)~dt.
$$


\begin{soln}
To show $(a)\implies (b)$, we have \[
||\nabla f(x)-\nabla f(y)|| \leq \beta ||x-y||
.\] 
Recall \[

.\] 

\end{soln}

\bigskip
\noindent
\item \textbf{(10 pts)} Show that the following statements are equivalent. 
\begin{enumerate}
\item $f$ is strongly convex with constant $\alpha$;
\item $(\nabla f(x) - \nabla f(y))^T(x-y) \geq \alpha \|x-y\|_2^2$ for all
  $x,y$;
\item $\nabla^2 f(x) \succeq \alpha I$ for all $x$;
\item $f(y) \geq f(x) + \nabla f(x)^T (y-x) + \frac{\alpha}{2}
  \|y-x\|_2^2$ for all $x,y$.
\end{enumerate}
We suggest that you prove (a) $\Rightarrow$ (b), (b)
$\Rightarrow$ (c), (c) $\Rightarrow$ (d), and (d) $\Rightarrow$ (a). You are welcome to try alternative approaches, but your response will be graded with respect to these 4 parts. 


\begin{soln}
YOUR SOLUTION HERE

\end{soln}

\end{enumerate}





\section{Projection to the PSD Cone (6 Pts) - Johnna}  


In this problem, we study how to project a given point onto a convex set. These kinds of projections will be used in projected gradient descent algorithms.



The $d \times d$-dimensional  PSD cone $\mathcal{P}$ is given by:
$$\mathcal{P} = \{M  \in \mathbb{R}^{d \times d} \mid M \succeq 0 \}.$$
Here, $M \succeq 0 $ means that $M$ is a symmetric, positive semi-definite matrix. Derive (with proof) a formula for $\Pi_{\mathcal{P}} (X) \doteq \argmin_{M \in \mathcal{P}}\|M - X\|_F^2$, where $X \in \mathbb{R}^{d \times d}$ is a symmetric matrix (not necessarily PSD) and $\|\cdot\|_F^2$ denotes the Frobenius norm.  You can use $X = U \Sigma U^{\top}$  as the eigen-decomposition of $X$, where $U$ consists of the eigenvectors and $\Sigma$ consists of the associated eigenvalues. 


\begin{soln}
   YOUR SOLUTION HERE
\end{soln}

\section{Convex-Concave Functions and Saddle-Points (Canary, Zixin)}
We say the function $f : \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}$ 
is \emph{convex-concave} if $f(x,z)$ is a concave function of $z$, for each fixed $x$, 
and a convex function of $x$, for each fixed $z$. \footnote{These types of functions arise in two-player zero sum games, where one player chooses $x$ and the other chooses $z$, but they have opposite utilities, meaning that the $X$-player wants to minimize $f(x,z)$, while the $Z$ player wants to maximize it. These functions also arise centrally in duality, encountered in the second half of the course.}
We also require its domain to have the product form 
$\mathrm{dom}\, f = A \times B$, where $A \subseteq \mathbb{R}^n$ and 
$B \subseteq \mathbb{R}^m$ are convex.

\begin{enumerate}
\item[(a)] 
Give a second-order condition for a twice differentiable function 
$f : \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}$ to be convex-concave, 
in terms of its Hessian $\nabla^2 f(x,z)$.

\item[(b)] 
Suppose that $f : \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}$ is convex-concave 
and differentiable, with $\nabla f(\tilde{x}, \tilde{z}) = 0$. 
Show that the \emph{saddle-point property} holds: for all $x,z$, we have
\[
f(\tilde{x},z) \leq f(\tilde{x}, \tilde{z}) \leq f(x, \tilde{z}).
\]

Show that this implies that $f$ satisfies the \emph{strong max-min property}:
\[
\sup_{z} \inf_{x} f(x,z) \;=\; \inf_{x} \sup_{z} f(x,z)
\]
(and their common value is $f(\tilde{x},\tilde{z})$).

\item[(c)] 
Now suppose that $f : \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R}$ is differentiable, 
but not necessarily convex-concave, and the saddle-point property holds at $\tilde{x}, \tilde{z}$:
\[
f(\tilde{x},z) \leq f(\tilde{x}, \tilde{z}) \leq f(x, \tilde{z})
\]
for all $x,z$. Show that $\nabla f(\tilde{x}, \tilde{z}) = 0$.
\end{enumerate}

\begin{soln}
 YOUR SOLUTION HERE
\end{soln}


\section{Step-Sizes and Optimization Algorithms (15 Pts) - Nuoya}  
\subsection{Polyak Step-Size (10 Pts)}
In our analysis of the subgradient method we began with the inequality:
\begin{align*}
\|x^{t+1} - x^*\|_2^2 \leq \|x^t - x^*\|_2^2 - 2 \eta_t (f(x^t) - f(x^*)) + \eta_t^2 \|g_{x^t}\|_2^2.
\end{align*}
Boris Polyak, who was a giant in the field of mathematical optimization, proposed an ``oracle'' step-size rule which simply chooses $\eta_t$ at each iteration to minimize the RHS above. This is known as the Polyak step-size, and requires one
to know the value of $f(x^*)$ (i.e. the optimal function value) or at least a lower bound on this quantity.

This sequence of step-sizes has many magical properties (for instance, it automatically adapts to things like smoothness and strong-convexity, giving algorithms which are optimal in each of these settings, without needing
to know the smoothness and strong-convexity parameters). 

\begin{enumerate}
\item Calculate the Polyak step-sizes $\eta_t$ above. Show that the Polyak step-sizes guarantee the following property:  
\begin{align*}
\|x^{t+1} - x^*\|_2^2 \leq \|x^t - x^*\|_2^2 - \frac{(f(x^t) - f(x^*))^2}{\|g_{x^t}\|_2^2}. 
\end{align*}
This in turn means that the Polyak step-sizes ensure that at each step we move closer to an optimal solution, i.e. every step makes some 
progress towards the optimal solution.



\begin{soln}

\end{soln}


\item Let us suppose that we are optimizing a function which is $G$-Lipschitz. Give a (tight) upper bound (it should match the best rate we've given in lecture) for the subgradient
method for $f(x^{\text{best}}) - f(x^*)$. 

\begin{soln}

\end{soln}

\item Suppose we do not know $f(x^*)$ exactly but we have a known lower bound
$\ell$ with $\ell \le f(x^*)$. Define the slack
$\delta := f(x^*) - \ell \ge 0$. Run the Polyak rule using $\ell$ in place of $f(x^*)$ and show that after $k$ iterations the best iterate
\[
x^{\text{best}}:=\arg\min_{0\le t\le k-1} f(x^t)
\]
satisfies the bound
\[
f(x^{\text{best}})-f(x^*) \;\le\; \sqrt{\,\delta^2 \;+\; \frac{G^2\|x^0-x^*\|_2^2}{k}\, }.
\]

\begin{soln}

\end{soln}


\end{enumerate}

\subsection{Step-Size Schedule (5 Pts)}
In one of the lectures, we analyzed the subgradient method. We proved that if function $f$ is Lipschitz continuous, convex, and
\begin{align*}
\sum_{t=0}^{\infty} \eta_t &= \infty,  \\
\sum_{t=0}^{\infty} \eta_t^2 &< \infty,
\end{align*}
then the subgradient method converges to the optimum. We can also note that the step-size schedule of  $\eta_t = 1/\sqrt{t}$ also leads to convergence, but it does not satisfy 
the above two conditions.
Show that the following two conditions suffice to ensure convergence for the subgradient method: 
\begin{align*}
\sum_{t=0}^{\infty} \eta_t &= \infty,  \\
\lim_{t \rightarrow \infty} \eta_t &= 0.
\end{align*}

{\bf Hint: } Try to argue that under these conditions, 
\begin{align*}
\lim_{T \rightarrow \infty} \frac{\sum_{t=0}^{T} \eta_t^2}{\sum_{t=0}^{T} \eta_t} = 0.
\end{align*}

\begin{soln}
   
\end{soln}

\newpage
\section{Effects of Learning Rate on Optimization Performance (25 Pts) - Michael} 

In this problem, we will further explore (stochastic) gradient descent, some failure modes, and the crucial role that learning rate plays. 

\subsection{Quadratic Bowl Function (15 Pts)}

In this subpart, we will consider the following function (called the ``quadratic bowl'')
\[ f(x, y) = ax^2 + by^2. \]

Two or three sentences for each of the following questions is sufficient. 

\textbf{For the questions below suppose that $a = 1, b=2$.}
\begin{enumerate}
    \item What are the relevant convexity and smoothness properties of $f$? (eg: is it strictly/strongly convex, is it Lipschitz, etc.?) As a result, using the bound of gradient descent that we proved in class for this function family, what does the theory tell us the learning rate should be? Given this learning
    rate, what do we expect the convergence rate to be?
    
\begin{soln}
YOUR SOLUTION HERE
\end{soln}
    
\item For a given $(x,y)$, manually derive the gradient of $f$. Then, implement the \texttt{gd\_f} function in \texttt{bowl.py}: gradient descent of $f$ from any starting point $\bm{x_0}$ given any learning rate $\alpha$ 

\begin{soln}
YOUR SOLUTION HERE
\end{soln}

\item For $\bm{x_0} = (3,-2)$, find a fixed learning rate such that $\texttt{gd\_f}$ converges extremely quickly ($\sim3$ steps). For full credit, you need to be within $5\%$ of the optimal value. Does the learning rate you found align with what the theory predicts should work well? 



\begin{soln}
YOUR SOLUTION HERE
\end{soln}

\item Plot (1) the level sets of $f$; (2) the trajectories of $\bm{x_t}$ overlaid on the level set plot. What do you observe? (some questions to think about: \textit{what if we increased $b$ to 20 and kept the same learning rate? how does the shape of the curve affect convergence of gradient descent assuming we use the ``optimal'' learning rate?})

\begin{soln}
YOUR SOLUTION HERE
\end{soln}

\end{enumerate}

\textbf{For the questions below suppose that $a=1, b=20$. And $\bm{x_0} = (3,-2)$}

\begin{enumerate}
\item[5.] Plot the level sets of $f$ now. How did the shape of the curve change? 

\begin{soln}
YOUR SOLUTION HERE 
\end{soln}
\item[6.] Again, based on the theory we derived in class what should we set the learning rate to now? Is it a different learning rate from Q5.1.1? Why?

\begin{soln}
YOUR SOLUTION HERE.
\end{soln}

\item[7.] Find a learning rate where gradient descent converges (should take roughly 80 steps). Plot the trajectories of $\bm{x_t}$ over the level set again, what do you notice? Why could we not converge as quickly as before when $b=2$. Does this agree with your intuitions in Q5.1.4?

\begin{soln}
YOUR SOLUTION HERE 
\end{soln}

\end{enumerate}

\textbf{Now for the finale}, based on our analysis above, make a \textit{very simple} modification to the gradient descent algorithm (write your implementation in \texttt{gd\_f\_better}) such that running your new optimization algorithm will allow us to converge to the optimum in less than 10 steps. 

Describe the changes that you made and plot the trajectory of $\bm{x_t}$ on the level set plot of $f$. 

\textit{Hints:}
{\em
\begin{enumerate}[nosep]
    \item Modify how gradient descent uses the learning rate. 
    \item The way you set your learning rate should not depend on the initial point, $\bm{x_0}$.
\end{enumerate}
}

\begin{soln}
YOUR SOLUTION HERE
\end{soln}



\subsection{Lasso Regression and Overparameterized Problems (10 Pts)}

In this question, we will further explore Lasso regression as discussed in class. Lasso not only has nice geometric properties (i.e. it is convex; differentiable almost everywhere), but also nice statistical ones\footnote{You can read more about this here: \url{https://www.stat.cmu.edu/~larry/=stat705/Lecture22.pdf}.}.

In this subpart, we will explore using Lasso+subgradient descent to solve a real-world regression problem: predicting the value of a house, given some features (lot area, year built, number of floors, etc.). 

The regression you will be trying to learn is ``overparameterized'' meaning that the system we are trying to learn is underdetermined (i.e. more features than data points; this type of setup is very common nowadays\footnote{\url{https://openai.com/index/deep-double-descent/}}). In this case, Lasso will be particularly helpful.

As a reminder, here is the Lasso loss function:
given a dataset with features matrix $X \in \mathbb{R}^{n \times d}$ and labels vector $y \in \mathbb{R}^n$,
\[ L(w) = \frac{1}{2n} \lVert Xw - y\rVert^2_2  + \alpha ||w||_1 \]
where $\alpha \geq 0$.

\begin{enumerate}
    \item Derive the subgradient of $L$. Implement both in \texttt{house.py}. 

\begin{soln}
YOUR SOLUTION HERE
\end{soln}
    \item Implement subgradient descent using $L, \partial L$.
    



    \item Perform a simple grid search over both the learning rate and $\alpha$. You should be able to hit $R^2 > 0.8$ on the test set. 


    
    \begin{enumerate}
        \item Search over $\alpha \in \{10^{k-5}\}_{k=0}^7$ and \[
        \texttt{lr} \in \{\texttt{1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2}\}\]
        \item Plot test $R^2$ as a function of both $\alpha$ and $\texttt{lr}$ (using a heatmap may be helpful here). Note that some combinations of these parameters will not converge. 
        \item Select the optimal hyperparameters from your grid search (optimal in terms of test $R^2$, you should be able to hit $R^2 > 0.75$ easily) and for this set of hyperparameters plot (1) both the training and test loss as a function of time; (2) the training and test $R^2$ as a function of time.
    \end{enumerate} 
    \item Look at your learned coefficients, which features are particularly predictive of the final sale price?
    \item Another way we could have implemented a sparse regression is through $L_0$ regularization:
    \[
    \tilde L(w) = \frac{1}{2n} \lVert Xw - y \rVert_2^2 + \alpha \sum_{i=1}^d \mathds{1}(|w_i | > 0).
    \]
    Show that for $\alpha > 0$, $\tilde L$ is not convex in $w$. [\textit{Hint: the best way to do this is through a counterexample example with an explicit setting of $X, y$, it is \textbf{not} true that the sum of a convex function with a non-convex one is not convex.}]

\begin{soln}
YOUR SOLUTION HERE
\end{soln}

\end{enumerate}
